{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL and Advanced DL: Домашнее задание 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второе домашнее задание опять посвящено игре; его базовая часть, надеюсь, не слишком большая, но я добавил опциональную часть, которая, думаю, должна быть достаточно интересной для любого слушателя. Как обычно, в качестве решения ожидается ссылка на jupyter-ноутбук на вашем github (или публичный, или с доступом для snikolenko); ссылку обязательно нужно прислать в виде сданного домашнего задания на портале Академии. Любые комментарии, новые идеи и рассуждения на тему, как всегда, категорически приветствуются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть первая: крестики-нолики при помощи Q-обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде, прилагающемся к последней лекции про обучение с подкреплением, реализован Environment для крестиков-ноликов, в котором можно при инициализации указывать разные размеры доски и условия победы, а также функции для рисования, в том числе с указанием оценки различных действий. С этим окружением все задания и связаны.\n",
    "\n",
    "1) Реализуйте обычное (табличное) Q-обучение. Обучите стратегии крестиков и ноликов для доски 3х3.\n",
    "\n",
    "2) Попробуйте обучить стратегии крестиков и ноликов для доски 4х4 и/или 5х5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Реализуйте обычное (табличное) Q-обучение. Обучите стратегии крестиков и ноликов для доски 3х3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем среду для крестиков ноликов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS, N_COLS, N_WIN = 3, 3, 3\n",
    "\n",
    "\n",
    "class TicTacToe(gym.Env):\n",
    "    def __init__(self, n_rows=N_ROWS, n_cols=N_COLS, n_win=N_WIN):\n",
    "        self.n_rows = n_rows\n",
    "        self.n_cols = n_cols\n",
    "        self.n_win = n_win\n",
    "\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.gameOver = False\n",
    "        self.boardHash = None\n",
    "        # ход первого игрока\n",
    "        self.curTurn = 1\n",
    "        self.emptySpaces = None\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def getEmptySpaces(self):\n",
    "        if self.emptySpaces is None:\n",
    "            res = np.where(self.board == 0)\n",
    "            self.emptySpaces = np.array([ (i, j) for i,j in zip(res[0], res[1]) ])\n",
    "        return self.emptySpaces\n",
    "\n",
    "    def makeMove(self, player, i, j):\n",
    "        self.board[i, j] = player\n",
    "        self.emptySpaces = None\n",
    "        self.boardHash = None\n",
    "\n",
    "    def getHash(self):\n",
    "        if self.boardHash is None:\n",
    "            self.boardHash = ''.join(['%s' % (x+1) for x in self.board.reshape(self.n_rows * self.n_cols)])\n",
    "        return self.boardHash\n",
    "\n",
    "    def isTerminal(self):\n",
    "        # проверим, не закончилась ли игра\n",
    "        cur_marks, cur_p = np.where(self.board == self.curTurn), self.curTurn\n",
    "        for i,j in zip(cur_marks[0], cur_marks[1]):\n",
    "#             print((i,j))\n",
    "            win = False\n",
    "            if i <= self.n_rows - self.n_win:\n",
    "                if np.all(self.board[i:i+self.n_win, j] == cur_p):\n",
    "                    win = True\n",
    "            if not win:\n",
    "                if j <= self.n_cols - self.n_win:\n",
    "                    if np.all(self.board[i,j:j+self.n_win] == cur_p):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j <= self.n_cols - self.n_win:\n",
    "                    if np.all(np.array([ self.board[i+k,j+k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j >= self.n_win-1:\n",
    "                    if np.all(np.array([ self.board[i+k,j-k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if win:\n",
    "                self.gameOver = True\n",
    "                return self.curTurn\n",
    "\n",
    "        if len(self.getEmptySpaces()) == 0:\n",
    "            self.gameOver = True\n",
    "            return 0\n",
    "\n",
    "        self.gameOver = False\n",
    "        return None\n",
    "\n",
    "    def printBoard(self):\n",
    "        for i in range(0, self.n_rows):\n",
    "            print('----'*(self.n_cols)+'-')\n",
    "            out = '| '\n",
    "            for j in range(0, self.n_cols):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('----'*(self.n_cols)+'-')\n",
    "\n",
    "    def getState(self):\n",
    "        return (self.getHash(), self.getEmptySpaces(), self.curTurn)\n",
    "\n",
    "    def action_from_int(self, action_int):\n",
    "        return ( int(action_int / self.n_cols), int(action_int % self.n_cols))\n",
    "\n",
    "    def int_from_action(self, action):\n",
    "        return action[0] * self.n_cols + action[1]\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.board[action[0], action[1]] != 0:\n",
    "            return self.getState(), -10, True, {}\n",
    "        self.makeMove(self.curTurn, action[0], action[1])\n",
    "        reward = self.isTerminal()\n",
    "        self.curTurn = -self.curTurn\n",
    "        return self.getState(), 0 if reward is None else reward, reward is not None, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.boardHash = None\n",
    "        self.gameOver = False\n",
    "        self.emptySpaces = None\n",
    "        self.curTurn = 1\n",
    "        \n",
    "    def state_to_array(self):\n",
    "        current = self.getState()[0]\n",
    "        ans = list()\n",
    "        for i in range(self.n_rows * self.n_cols):\n",
    "            ans.append(int(current[i]))\n",
    "            \n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не долго думая, написал агента для Q learning на основе 1 домашнего задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "#env = TicTacToeEnv(symbols=[2, 0], board_size=3, win_size=3)\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, tag=1, symbols=[2, 0], board_size=3, win_size=3, alpha=0.1, gamma=0.9):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.tag = tag\n",
    "        self.Q_table = defaultdict(lambda:1)\n",
    "        self.board_size = board_size\n",
    "        self.win_size = win_size\n",
    "        stuff = [1]\n",
    "        stuff.append(symbols[0])\n",
    "        stuff.append(symbols[1])\n",
    "        self.history = list()\n",
    "        \n",
    "        #for subset in tqdm(itertools.combinations_with_replacement(stuff, self.board_size * self.board_size)):\n",
    "        #    if subset not in tqdm(self.Q_table.keys()):\n",
    "        #        self.Q_table[subset] = 1\n",
    "        #        for pos in tqdm(itertools.permutations(subset, self.board_size * self.board_size)):\n",
    "        #            self.Q_table[pos] = 1     \n",
    "                    \n",
    "                    \n",
    "    def get_action(self, state, action_area, eps):\n",
    "        posible_states = dict()\n",
    "        if np.random.random() < eps:\n",
    "            next_action = np.random.choice(list(action_area))\n",
    "            action_area.remove(next_action)\n",
    "            new_state = state.copy()\n",
    "            new_state[next_action] = self.tag\n",
    "            self.history.append(tuple(new_state))\n",
    "        else:        \n",
    "            for i in range(len(state)):\n",
    "                if state[i] == 1:\n",
    "                    new_state = state.copy()\n",
    "                    new_state[i] = self.tag\n",
    "                    posible_states[tuple(new_state)] = self.Q_table[tuple(new_state)]\n",
    "\n",
    "            next_action = list(max(posible_states, key=posible_states.get))#next_action = list(posible_states.keys())[np.argmax(max(posible_states, key=posible_states.get))]\n",
    "        \n",
    "            self.history.append(tuple(next_action))\n",
    "            next_state = np.absolute(np.array(state) - np.array(next_action))\n",
    "\n",
    "            next_action = np.argmax(next_state)\n",
    "            action_area.remove(next_action)\n",
    "        \n",
    "        return next_action, action_area\n",
    "    \n",
    "    def update(self, reward):\n",
    "        for i in reversed(self.history):\n",
    "            reward = self.Q_table[i] + self.alpha * (reward - self.gamma * self.Q_table[i])\n",
    "            self.Q_table[i] = reward\n",
    "            \n",
    "        self.history = list()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_episode(env, agent_tic, agent_tac, eps_tic=0.2, eps_tac=0.2, render=True, batch_size=1):\n",
    "    rews1 = list()\n",
    "    rews2 = list()\n",
    "    for i in range(batch_size):\n",
    "        user = 0\n",
    "        done = False\n",
    "        reward = 0\n",
    "        state = env.reset()\n",
    "        action_area = set(np.arange(env.n_rows * env.n_cols))        \n",
    "        while not done:\n",
    "            if render:\n",
    "                env.render(mode=None)\n",
    "            if user == 0:\n",
    "                state = env.state_to_array()\n",
    "                #print(state, action_area)\n",
    "                choice, action_area = agent_tic.get_action(state, action_area, eps_tic)\n",
    "                state, reward, done, infos = env.step(env.action_from_int(choice))\n",
    "            elif user == 1:   \n",
    "                state = env.state_to_array()\n",
    "                #print(state, action_area)\n",
    "                choice, action_area = agent_tac.get_action(state, action_area, eps_tac)       \n",
    "                state, reward, done, infos = env.step(env.action_from_int(choice))\n",
    "\n",
    "            # If the game isn't over, change the current player\n",
    "\n",
    "            #print(reward)\n",
    "            if not done:\n",
    "                user = 0 if user == 1 else 1\n",
    "            else :\n",
    "                if reward == 0:\n",
    "                    reward1 = 0.5\n",
    "                    reward2 = 0.5\n",
    "                    agent_tic.update(reward1)\n",
    "                    agent_tac.update(reward2)\n",
    "\n",
    "                elif reward == -1:\n",
    "                    reward1 = -1\n",
    "                    reward2 = 1\n",
    "                    agent_tic.update(reward1)\n",
    "                    agent_tac.update(reward2)\n",
    "\n",
    "                elif reward == 1:\n",
    "                    reward1 = 1\n",
    "                    reward2 = -1\n",
    "                    agent_tic.update(reward1)\n",
    "                    agent_tac.update(reward2)\n",
    "        \n",
    "        rews1.append(reward1)\n",
    "        rews2.append(reward2)\n",
    "    \n",
    "    return np.mean(rews1), np.mean(rews2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe(n_rows=3, n_cols=3, n_win=3)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tic = Agent(tag=2) #-1\n",
    "agent_tac = Agent(tag=0) #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699b39dee811415097ca25be78374ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 20000\n",
    "\n",
    "\n",
    "\n",
    "tic_rewards = list()\n",
    "tac_rewards = list()\n",
    "\n",
    "rews1 = list()\n",
    "rews2 = list()\n",
    "\n",
    "exploration_rate_tic = 1\n",
    "exploration_rate_tac = 1\n",
    "\n",
    "rew_cum1 = 0\n",
    "rew_cum2 = 0\n",
    "for i in tqdm(range(n_episodes)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        exploration_rate_tic -= 0.01\n",
    "        #exploration_rate_tac -= 0.01\n",
    "    \n",
    "    rew1, rew2 = sample_episode(env, agent_tic, agent_tac, exploration_rate_tic, exploration_rate_tac, render=False, batch_size=4)\n",
    "    rew_cum1 += rew1\n",
    "    rew_cum2 += rew2\n",
    "    rews1.append(rew1)\n",
    "    rews2.append(rew2)\n",
    "    tic_rewards.append(rew_cum1 / (i+1))\n",
    "    tac_rewards.append(rew_cum2 / (i+1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "График среднего выигрыша для крестиков против случайного выбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x237d17a94c8>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tic_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь пробуем обучить играть ноликов против случайного соперника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tic = Agent(tag=2) #-1\n",
    "agent_tac = Agent(tag=0) #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3d00cf2846440a87aa92b9a82c1916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 50000\n",
    "\n",
    "\n",
    "\n",
    "tic_rewards = list()\n",
    "tac_rewards = list()\n",
    "\n",
    "rews1 = list()\n",
    "rews2 = list()\n",
    "\n",
    "exploration_rate_tic = 1\n",
    "exploration_rate_tac = 1\n",
    "\n",
    "rew_cum1 = 0\n",
    "rew_cum2 = 0\n",
    "for i in tqdm(range(n_episodes)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        #exploration_rate_tic -= 0.01\n",
    "        exploration_rate_tac -= 0.01\n",
    "    \n",
    "    rew1, rew2 = sample_episode(env, agent_tic, agent_tac, exploration_rate_tic, exploration_rate_tac, render=False, batch_size=4)\n",
    "    rew_cum1 += rew1\n",
    "    rew_cum2 += rew2\n",
    "    rews1.append(rew1)\n",
    "    rews2.append(rew2)\n",
    "    tic_rewards.append(rew_cum1 / (i+1))\n",
    "    tac_rewards.append(rew_cum2 / (i+1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "График среднего выигрыша для ноликов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xa367280>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tac_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Попробуйте обучить стратегии крестиков и ноликов для доски 4х4 и/или 5х5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить для доски 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe(n_rows=4, n_cols=4, n_win=4)\n",
    "env.reset()\n",
    "agent_tic = Agent(tag=2, symbols=[2, 0], board_size=4, win_size=4, alpha=0.1, gamma=0.9) #-1\n",
    "agent_tac = Agent(tag=0, symbols=[2, 0], board_size=4, win_size=4, alpha=0.1, gamma=0.9) #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bc619d12584eed9e77806850230e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 100000\n",
    "\n",
    "\n",
    "\n",
    "tic_rewards = list()\n",
    "tac_rewards = list()\n",
    "\n",
    "rews1 = list()\n",
    "rews2 = list()\n",
    "\n",
    "exploration_rate_tic = 1\n",
    "exploration_rate_tac = 1\n",
    "\n",
    "rew_cum1 = 0\n",
    "rew_cum2 = 0\n",
    "for i in tqdm(range(n_episodes)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        exploration_rate_tic -= 0.01\n",
    "        #exploration_rate_tac -= 0.01\n",
    "    \n",
    "    rew1, rew2 = sample_episode(env, agent_tic, agent_tac, exploration_rate_tic, exploration_rate_tac, render=False, batch_size=4)\n",
    "    rew_cum1 += rew1\n",
    "    rew_cum2 += rew2\n",
    "    rews1.append(rew1)\n",
    "    rews2.append(rew2)\n",
    "    tic_rewards.append(rew_cum1 / (i+1))\n",
    "    tac_rewards.append(rew_cum2 / (i+1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средний выигрыш для крестиков против случайного соперника на доске 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x237d181d2c8>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tic_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим для доски 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe(n_rows=5, n_cols=5, n_win=5)\n",
    "env.reset()\n",
    "agent_tic = Agent(tag=2, symbols=[2, 0], board_size=5, win_size=5, alpha=0.1, gamma=0.9) #-1\n",
    "agent_tac = Agent(tag=0, symbols=[2, 0], board_size=5, win_size=5, alpha=0.1, gamma=0.9) #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399ceec0b2434b3f8c8610a00f1320cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 100000\n",
    "\n",
    "\n",
    "\n",
    "tic_rewards = list()\n",
    "tac_rewards = list()\n",
    "\n",
    "rews1 = list()\n",
    "rews2 = list()\n",
    "\n",
    "exploration_rate_tic = 1\n",
    "exploration_rate_tac = 1\n",
    "\n",
    "rew_cum1 = 0\n",
    "rew_cum2 = 0\n",
    "for i in tqdm(range(n_episodes)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        exploration_rate_tic -= 0.01\n",
    "        #exploration_rate_tac -= 0.01\n",
    "    \n",
    "    rew1, rew2 = sample_episode(env, agent_tic, agent_tac, exploration_rate_tic, exploration_rate_tac, render=False, batch_size=4)\n",
    "    rew_cum1 += rew1\n",
    "    rew_cum2 += rew2\n",
    "    rews1.append(rew1)\n",
    "    rews2.append(rew2)\n",
    "    tic_rewards.append(rew_cum1 / (i+1))\n",
    "    tac_rewards.append(rew_cum2 / (i+1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средний выигрыш для крестиков против случайного соперника на доске 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x237e8dc3688>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tic_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если для доски 4 на 4 крестики имели средний выигрыш 0.6 (за победу 1) на 100к эпизодов, то на доске 5 на 5 средний выигрыш уже около 0.4. Такого количества эпизодов не хватает для того, чтобы агент сошелся"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть вторая: добавим нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте нейронную сеть для метода DQN на доске для крестиков-ноликов. Не буду ограничивать фантазию, но кажется, что свёртки 3х3 здесь должны неплохо работать (в том числе обобщаться на доски размера побольше).\n",
    "\n",
    "1) Реализуйте DQN с нейронной сетью, обучите стратегии крестиков и ноликов. Замечание: скорее всего, experience replay потребуется сразу же.\n",
    "\n",
    "2) Реализуйте Double DQN и/или Dueling DQN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Реализуйте DQN с нейронной сетью, обучите стратегии крестиков и ноликов. Замечание: скорее всего, experience replay потребуется сразу же."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем сеть DQN и агента с experience replay. Experience replay построим на основе collections.deque, он позволяет задать максимальную длину и сам зациклится и будет - как раз это и нужно, а тут работает из коробки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUF_SIZE = 512\n",
    "N_COLS_ROWS_WINS = 3\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, dim=512, kernel_size=(3,3), n_channels=N_COLS_ROWS_WINS, out_channels=N_COLS_ROWS_WINS * N_COLS_ROWS_WINS):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=dim, kernel_size=kernel_size)\n",
    "        self.fc1 = nn.Linear(dim, dim * 2)\n",
    "        self.fc2 = nn.Linear(dim * 2, dim)\n",
    "        self.fc3 = nn.Linear(dim, out_channels)     \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)).squeeze(-1).squeeze(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        return self.fc3(x)\n",
    "    \n",
    "\n",
    "class DQN_Agent:\n",
    "    def __init__(self, size, kernel_size=(3,3), n_channels=N_COLS_ROWS_WINS, out_channels=N_COLS_ROWS_WINS * N_COLS_ROWS_WINS):\n",
    "        self.size = size\n",
    "        self.replay_buffer = deque(maxlen=BUF_SIZE)\n",
    "        self.state = None\n",
    "        self.next_state = None\n",
    "        self.action = None\n",
    "        self.reward = None\n",
    "        self.model = DQN()\n",
    "        self.optim = optim.Adam(self.model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    def update_replay(self, transition):\n",
    "        self.replay_buffer.append((transition[0], transition[1], transition[2], transition[3]))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.replay_buffer, batch_size)\n",
    "    \n",
    "    def update(self, next_state, action, reward):\n",
    "        next_state_ = np.zeros((3,N_COLS_ROWS_WINS,N_COLS_ROWS_WINS))\n",
    "        next_state_[0,:,:] = (next_state == 1).astype(float)\n",
    "        next_state_[1,:,:] = (next_state == -1).astype(float)\n",
    "        next_state_[2,:,:] = (next_state == 0).astype(float)\n",
    "        if self.state is not None:\n",
    "            self.update_replay((self.state, next_state_, self.action, reward))\n",
    "            \n",
    "        self.state = next_state_\n",
    "        self.action = action\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем опять обучать играть агентов против случайного соперника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  \n",
    "from IPython import display\n",
    "from ipywidgets import Output\n",
    "\n",
    "\n",
    "env = TicTacToe(n_rows=N_COLS_ROWS_WINS, n_cols=N_COLS_ROWS_WINS, n_win=N_COLS_ROWS_WINS)    \n",
    "LR = 1e-6\n",
    "WEIGHT_DECAY = 1e-9\n",
    "HIDDEN_SIZE = 512\n",
    "batch_size = 128\n",
    "criterion = F.l1_loss\n",
    "\n",
    "tic_agent = DQN_Agent(size=HIDDEN_SIZE, n_channels=3, out_channels=N_COLS_ROWS_WINS*N_COLS_ROWS_WINS)\n",
    "tac_agent = DQN_Agent(size=HIDDEN_SIZE, n_channels=3, out_channels=N_COLS_ROWS_WINS*N_COLS_ROWS_WINS)\n",
    "\n",
    "n_epochs = 10000\n",
    "\n",
    "def DQN_train(env, tic_agent, tac_agent, criterion, n_epochs):\n",
    "    rews1 = list()\n",
    "    rews2 = list()\n",
    "\n",
    "    rew_cum1 = 0\n",
    "    rew_cum2 = 0\n",
    "\n",
    "    eps = 0.5\n",
    "    gamma = 0.9\n",
    "\n",
    "    history_rews1 = list()\n",
    "    history_rews2 = list()\n",
    "    y_rews = list()\n",
    "\n",
    "    out = Output()\n",
    "    display.display(out)\n",
    "    for i in tqdm(range(n_epochs)):\n",
    "\n",
    "        env.reset()\n",
    "        tic_agent.model.eval()\n",
    "        tac_agent.model.eval()\n",
    "        game_hash, empty_spaces, turn = env.getState()\n",
    "        state = env.board.copy()\n",
    "\n",
    "        user = 0\n",
    "        done=False\n",
    "\n",
    "        tic_agent.state = None\n",
    "        tic_agent.action = None\n",
    "\n",
    "        tac_agent.state = None\n",
    "        tac_agent.action = None\n",
    "\n",
    "        #Сэмплируем эпизод\n",
    "        while not done:\n",
    "            if random.random() < (1 - eps):\n",
    "                state_ = np.zeros((3,N_COLS_ROWS_WINS,N_COLS_ROWS_WINS))\n",
    "                state_[0,:,:] = (state == 1).astype(float)\n",
    "                state_[1,:,:] = (state == -1).astype(float)\n",
    "                state_[2,:,:] = (state == 0).astype(float)\n",
    "                state_ = torch.FloatTensor([state_])\n",
    "                if user == 0:\n",
    "                    #tic_agent.model.eval()\n",
    "                    action = tic_agent.model(state_).detach().max(1)[1][0].item()\n",
    "\n",
    "                else:\n",
    "                    #tac_agent.model.eval()\n",
    "                    action = tac_agent.model(state_).detach().max(1)[1][0].item()                \n",
    "\n",
    "            else:\n",
    "                possible_states = np.where(np.array(list(game_hash)) == '1')[0]\n",
    "                action = random.choice(possible_states)\n",
    "\n",
    "            if user == 0:\n",
    "                tic_agent.update(state, action, 0)\n",
    "            else:\n",
    "                tac_agent.update(state, action, 0)       \n",
    "\n",
    "            (game_hash, empty_spaces, turn), reward , done, _ = env.step(env.action_from_int(action))\n",
    "            state = env.board.copy()     \n",
    "\n",
    "            if not done:\n",
    "                user = 0 if user == 1 else 1    \n",
    "\n",
    "        #Добавляем опыт в experience replay\n",
    "        if reward == -10:\n",
    "            if user == 0:\n",
    "                tic_agent.update(state, action, reward)\n",
    "            else:\n",
    "                tac_agent.update(state, action, reward)\n",
    "        else:    \n",
    "            tic_agent.update(state, action, reward)\n",
    "            tac_agent.update(state, action, -reward)               \n",
    "\n",
    "        \n",
    "        #Будем обновлять только с того момента, как наш буффер заполнится. На самом деле здесь можно было поступить по другому\n",
    "        #и изначально насэмплировать буффер на необученном агенте\n",
    "        if len(tic_agent.replay_buffer) >= batch_size:\n",
    "            states, next_states, actions, rewards = list(zip(*tic_agent.sample(batch_size)))\n",
    "\n",
    "\n",
    "            batch_state = torch.FloatTensor(states)\n",
    "            batch_next_state = torch.FloatTensor(next_states)\n",
    "            batch_actions = torch.LongTensor(actions)\n",
    "            batch_reward = torch.FloatTensor(rewards)\n",
    "\n",
    "            tic_agent.model.train()\n",
    "            Q = tic_agent.model(batch_state).gather(1, batch_actions.view(-1, 1)).flatten()\n",
    "            Qmax = tic_agent.model(batch_next_state).detach().max(dim=1)[0]\n",
    "            Qnext = batch_reward + (gamma * Qmax)\n",
    "\n",
    "            loss = criterion(Q, Qnext)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            tic_agent.optim.step()\n",
    "            tic_agent.optim.zero_grad()   \n",
    "\n",
    "            rews1.append(loss.item())\n",
    "\n",
    "        if len(tac_agent.replay_buffer) >= batch_size:\n",
    "            states, next_states, actions, rewards = list(zip(*tac_agent.sample(batch_size)))\n",
    "\n",
    "\n",
    "            batch_state = torch.FloatTensor(states)\n",
    "            batch_next_state = torch.FloatTensor(next_states)\n",
    "            batch_actions = torch.LongTensor(actions)\n",
    "            batch_reward = torch.FloatTensor(rewards)\n",
    "\n",
    "            tac_agent.model.train()\n",
    "            Q = tac_agent.model(batch_state).gather(1, batch_actions.view(-1, 1)).flatten()\n",
    "            Qmax = tac_agent.model(batch_next_state).detach().max(dim=1)[0]\n",
    "            Qnext = batch_reward + (gamma * Qmax)\n",
    "\n",
    "            loss = criterion(Q, Qnext)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            tac_agent.optim.step()\n",
    "            tac_agent.optim.zero_grad()   \n",
    "\n",
    "            rews2.append(loss.item())\n",
    "        \n",
    "        #Попробуем сыграть по очереди за крестиков и за ноликов\n",
    "        if (i + 1) % 100 == 0:\n",
    "\n",
    "            tic_agent.model.eval()\n",
    "            tac_agent.model.eval()\n",
    "\n",
    "            rews1 = list()\n",
    "            rews2 = list()\n",
    "\n",
    "            n_hands = 128\n",
    "\n",
    "            for j in range(n_hands):\n",
    "                env.reset()\n",
    "                game_hash, empty_spaces, turn = env.getState()\n",
    "                state = env.board\n",
    "                done = False        \n",
    "                user = 0\n",
    "\n",
    "                while not done:\n",
    "                    if user == 0:\n",
    "                        state_ = np.zeros((3,N_COLS_ROWS_WINS,N_COLS_ROWS_WINS))\n",
    "                        state_[0,:,:] = (state == 1).astype(float)\n",
    "                        state_[1,:,:] = (state == -1).astype(float)\n",
    "                        state_[2,:,:] = (state == 0).astype(float)                    \n",
    "                        state_ = torch.FloatTensor([state_])\n",
    "                        action = tic_agent.model(state_).detach().max(1)[1][0].item()\n",
    "                    else:\n",
    "                        possible_states = np.where(np.array(list(game_hash)) == '1')[0]\n",
    "                        action = random.choice(possible_states) \n",
    "\n",
    "                    (game_hash, empty_spaces, turn), reward , done, _ = env.step(env.action_from_int(action))\n",
    "                    state = env.board.copy()     \n",
    "\n",
    "                    if not done:\n",
    "                        user = 0 if user == 1 else 1    \n",
    "\n",
    "                if reward == -1 or reward == -10:\n",
    "                    reward = 0\n",
    "\n",
    "                rews1.append(reward)\n",
    "\n",
    "                env.reset()\n",
    "                game_hash, empty_spaces, turn = env.getState()\n",
    "                state = env.board\n",
    "                done = False        \n",
    "                user = 0\n",
    "\n",
    "                while not done:\n",
    "                    if user == 1:\n",
    "                        state_ = np.zeros((3,N_COLS_ROWS_WINS,N_COLS_ROWS_WINS))\n",
    "                        state_[0,:,:] = (state == 1).astype(float)\n",
    "                        state_[1,:,:] = (state == -1).astype(float)\n",
    "                        state_[2,:,:] = (state == 0).astype(float)                    \n",
    "                        state_ = torch.FloatTensor([state_])\n",
    "                        action = tac_agent.model(state_).detach().max(1)[1][0].item()\n",
    "                    else:\n",
    "                        possible_states = np.where(np.array(list(game_hash)) == '1')[0]\n",
    "                        action = random.choice(possible_states) \n",
    "\n",
    "                    (game_hash, empty_spaces, turn), reward , done, _ = env.step(env.action_from_int(action))\n",
    "                    state = env.board.copy() \n",
    "                    reward *= -1\n",
    "\n",
    "                    if not done:\n",
    "                        user = 0 if user == 1 else 1    \n",
    "\n",
    "                if reward == -1 or reward == 10:\n",
    "                    reward = 0\n",
    "                \n",
    "\n",
    "                rews2.append(reward)  \n",
    "\n",
    "            #if np.mean(rews1) > 0 or np.mean(rews2) > 0:\n",
    "            #    print(np.mean(rews1), np.mean(rews2))\n",
    "\n",
    "            history_rews1.append(np.mean(rews1))\n",
    "            history_rews2.append(np.mean(rews2))\n",
    "            y_rews.append(i)\n",
    "            with out:\n",
    "                display.clear_output(wait=True)\n",
    "                plt.title(\"DQN, iteration \" + str(i))\n",
    "                plt.plot(y_rews, history_rews1, label='tic')\n",
    "                plt.plot(y_rews, history_rews2, label='tac')\n",
    "                plt.legend()\n",
    "                plt.draw()\n",
    "                plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv1): Conv2d(3, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_agent.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95ffbe8286d4c80bba326b112a18146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7993518c25e1402bb9d36336be6af8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DQN_train(env, tic_agent, tac_agent, criterion, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить агентов для доски 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COLS_ROWS_WINS = 4\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, dim_1=32, dim_2=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=dim_1, kernel_size=(3, 3))\n",
    "        self.conv2 = nn.Conv2d(in_channels=dim_1, out_channels=dim_2, kernel_size=(2, 2))\n",
    "        self.fc1 = nn.Linear(dim_2, dim_2 * 2)\n",
    "        self.fc2 = nn.Linear(dim_2 * 2, dim_2 * 2)\n",
    "        self.fc3 = nn.Linear(dim_2 * 2, N_COLS_ROWS_WINS * N_COLS_ROWS_WINS)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x)).squeeze(-1).squeeze(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        return self.fc3(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv1): Conv2d(3, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_agent.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c176c641274b4ba0d3706008e4e71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19c2bfa68b04d80819d4b674ff25055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env = TicTacToe(n_rows=N_COLS_ROWS_WINS, n_cols=N_COLS_ROWS_WINS, n_win=N_COLS_ROWS_WINS)    \n",
    "LR = 1e-5\n",
    "WEIGHT_DECAY = 1e-9\n",
    "HIDDEN_SIZE = 512\n",
    "batch_size = 128\n",
    "criterion = F.l1_loss\n",
    "\n",
    "tic_agent = DQN_Agent(size=HIDDEN_SIZE, n_channels=3, out_channels=N_COLS_ROWS_WINS*N_COLS_ROWS_WINS)\n",
    "tac_agent = DQN_Agent(size=HIDDEN_SIZE, n_channels=3, out_channels=N_COLS_ROWS_WINS*N_COLS_ROWS_WINS)\n",
    "\n",
    "n_epochs = 10000\n",
    "\n",
    "DQN_train(env, tic_agent, tac_agent, criterion, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Реализуйте Double DQN и/или Dueling DQN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем Dueling DQN, для этого нам понадобится 2 сети: первая будет считать Value function, а вторая Advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COLS_ROWS_WINS = 3\n",
    "\n",
    "class Value(nn.Module):\n",
    "    def __init__(self, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size * 2)\n",
    "        self.fc2 = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.fc3 = nn.Linear(hidden_size * 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        return F.relu(self.fc3(x))\n",
    "    \n",
    "class Advantage(nn.Module):\n",
    "    def __init__(self, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size * 2)\n",
    "        self.fc2 = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.fc3 = nn.Linear(hidden_size * 2, N_COLS_ROWS_WINS * N_COLS_ROWS_WINS)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        return F.relu(self.fc3(x))\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=hidden_size, kernel_size=(3, 3))  \n",
    "        self.value = Value()\n",
    "        self.advantage = Advantage()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.squeeze(-1).squeeze(-1)\n",
    "        advantage = self.advantage(x)\n",
    "        value = self.value(x)\n",
    "        return value + (advantage - advantage.mean(dim=1, keepdim=True).expand(x.size(0), N_COLS_ROWS_WINS * N_COLS_ROWS_WINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cd3f11b91849f786c25883ba61168e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5768e44d348a4ef4a4fb4947f852f26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "env = TicTacToe(n_rows=N_COLS_ROWS_WINS, n_cols=N_COLS_ROWS_WINS, n_win=N_COLS_ROWS_WINS)    \n",
    "LR = 1e-5\n",
    "WEIGHT_DECAY = 1e-9\n",
    "HIDDEN_SIZE = 512\n",
    "batch_size = 128\n",
    "criterion = F.l1_loss\n",
    "\n",
    "tic_agent = DQN_Agent(size=HIDDEN_SIZE, n_channels=3, out_channels=N_COLS_ROWS_WINS*N_COLS_ROWS_WINS)\n",
    "tac_agent = DQN_Agent(size=HIDDEN_SIZE, n_channels=3, out_channels=N_COLS_ROWS_WINS*N_COLS_ROWS_WINS)\n",
    "\n",
    "n_epochs = 10000\n",
    "\n",
    "DQN_train(env, tic_agent, tac_agent, criterion, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть третья: расширим и углубим поиск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Крестики-нолики -- это, конечно, далеко не го, и обычный альфа-бета поиск с отсечением здесь наверняка может работать идеально вплоть до довольно больших досок. Однако мы всё-таки для этого учебного задания будем реализовывать более практически релевантный метод MCTS -- заодно фактически получится и упражнение на многоруких бандитов.\n",
    "\n",
    "5) Реализуйте rollouts со случайной стратегией и (опционально) rollouts с неслучайной, но простой стратегией (например, основанной на дополнении нескольких паттернов или на Q-функции, которая у вас получилась в первом пункте).\n",
    "\n",
    "6) Реализуйте MCTS-поиск с этими rollouts для крестиков-ноликов на досках разного размера, сравните полученные стратегии между собой и со стратегиями, обученными в первых двух частях.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Реализуйте rollouts со случайной стратегией и (опционально) rollouts с неслучайной, но простой стратегией (например, основанной на дополнении нескольких паттернов или на Q-функции, которая у вас получилась в первом пункте)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем Агента с rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class Agent_Rollouts(Agent):\n",
    "    def get_action(self, env, action_area):\n",
    "        tmp_env = deepcopy(env)\n",
    "        rewards = dict()\n",
    "        user = 0\n",
    "        for i in list(action_area):\n",
    "            entry_point_state = deepcopy(tmp_env)\n",
    "            state, reward, done, infos = entry_point_state.step(entry_point_state.action_from_int(i))\n",
    "            if not done:\n",
    "                evaluate_env = deepcopy(entry_point_state)\n",
    "                eval_action_area = deepcopy(action_area)\n",
    "                eval_action_area.remove(i)\n",
    "                eval_done = False\n",
    "                \n",
    "                while eval_done == False:\n",
    "                    eval_next_action = np.random.choice(list(eval_action_area))\n",
    "                    eval_action_area.remove(eval_next_action)      \n",
    "                    eval_state, eval_reward, eval_done, _ = evaluate_env.step(evaluate_env.action_from_int(eval_next_action))\n",
    "                \n",
    "                    if not done:\n",
    "                        user = 0 if user == 1 else 1\n",
    "                \n",
    "                if user == 0:\n",
    "                    rewards[i] = reward\n",
    "                else:\n",
    "                    rewards[i] = -reward     \n",
    "                    \n",
    "                if not done:\n",
    "                    user = 0 if user == 1 else 1\n",
    "            #print(i)\n",
    "            #entry_point_state.printBoard()\n",
    "        rewards[i] = reward\n",
    "        return max(rewards, key=rewards.get)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_episode(env, agent, n_batches=32):\n",
    "    rewards = list()\n",
    "    for i in range(n_batches):\n",
    "        env.reset()\n",
    "        state = env.state_to_array()\n",
    "        action_area = set(np.arange(env.n_rows * env.n_cols)) \n",
    "\n",
    "        user = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            if user == 0:\n",
    "                next_action = agent.get_action(env, action_area)\n",
    "                action_area.remove(next_action)\n",
    "                state, reward, done, infos = env.step(env.action_from_int(next_action))\n",
    "                #env.printBoard()\n",
    "\n",
    "            else:\n",
    "                next_action = np.random.choice(list(action_area))\n",
    "                action_area.remove(next_action)   \n",
    "                state, reward, done, infos = env.step(env.action_from_int(next_action))\n",
    "                #env.printBoard()\n",
    "\n",
    "            if not done:\n",
    "                user = 0 if user == 1 else 1    \n",
    "            else:\n",
    "                if reward == 0:\n",
    "                    reward = 0.5\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca0439fe9c349c294168657eb9e23d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Победы:  0.5093333333333333  Ничьи:  0.06933333333333333  Поражения:  0.0\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 3000\n",
    "N_COLS_ROWS_WINS = 3\n",
    "env = TicTacToe(n_rows=N_COLS_ROWS_WINS, n_cols=N_COLS_ROWS_WINS, n_win=N_COLS_ROWS_WINS)    \n",
    "\n",
    "rews = list()\n",
    "rews_cum = list()\n",
    "rew_c = 0\n",
    "\n",
    "statistics = defaultdict(int)\n",
    "agent = Agent_Rollouts()\n",
    "\n",
    "for i in tqdm(range(n_episodes)):\n",
    "    \n",
    "    rew = sample_episode(env, agent, n_batches=1)\n",
    "    statistics[rew] += 1\n",
    "    rew_c += rew\n",
    "\n",
    "    rews.append(rew)\n",
    "    rews_cum.append(rew_c / (i+1))\n",
    "\n",
    "    \n",
    "print('Победы: ', statistics[1] / n_episodes, ' Ничьи: ', statistics[0.5] / n_episodes, ' Поражения: ', statistics[0] / n_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x238d6b07a88>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rews_cum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
